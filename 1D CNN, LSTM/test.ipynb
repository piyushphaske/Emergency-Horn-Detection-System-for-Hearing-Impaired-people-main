{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.9184433e+02  4.6035007e+01 -3.6251511e+01 -3.7054634e+01\n",
      " -4.6551708e+01 -2.2198952e+01  8.6737041e+00  3.1192137e+01\n",
      "  2.0635069e+01 -2.6964619e+00 -3.0393009e+01 -2.7804222e+01\n",
      " -1.8278316e-01  1.3304220e+01  1.1180802e+01 -3.4404960e-01\n",
      "  1.5602996e+00 -1.2607950e-01 -4.5270863e+00  2.9653034e+00\n",
      "  5.6978469e+00  1.7867261e+00  9.0346295e-01  7.0495337e-01\n",
      "  2.6810923e+00  4.2743378e+00 -9.9598074e-01 -1.8722837e+00\n",
      "  1.9228293e+00 -7.2615938e+00 -5.9661994e+00  8.2451391e+00\n",
      "  2.6393886e+00  8.0525324e-02 -5.7541651e-01 -1.2452264e+00\n",
      "  2.7321884e-01  3.9579999e-01  1.2603654e+00  1.8978856e+00\n",
      "  1.0581354e+00 -1.3136144e+00  1.4190880e+00  1.7848067e+00\n",
      " -1.1874753e+00 -1.4837910e+00 -1.8483961e+00  7.4064869e-01\n",
      " -3.2879169e+00 -1.3570244e+00  4.3589478e+00  1.5607371e+00\n",
      "  1.3384807e+00  2.8039381e-01  1.1386129e+00  1.3377626e-01\n",
      "  3.6440060e-01  2.4644117e+00 -3.7522811e-01  1.0571265e+00\n",
      " -1.1832542e+00 -5.0374310e-02  1.2136407e+00 -3.2118899e-01\n",
      " -4.8231453e-01 -1.0542123e+00  3.0117777e-01 -1.9164909e+00\n",
      "  1.4462500e+00  6.2812352e-01 -6.0211265e-01  2.1912541e+00\n",
      "  5.4010445e-01  8.7811184e-01  8.3343095e-01  3.0447152e-01\n",
      " -3.1240159e-01 -5.6356990e-01 -3.2126442e-01 -8.4462905e-01]\n",
      "[[-3.9184433e+02  4.6035007e+01 -3.6251511e+01 -3.7054634e+01\n",
      "  -4.6551708e+01 -2.2198952e+01  8.6737041e+00  3.1192137e+01\n",
      "   2.0635069e+01 -2.6964619e+00 -3.0393009e+01 -2.7804222e+01\n",
      "  -1.8278316e-01  1.3304220e+01  1.1180802e+01 -3.4404960e-01\n",
      "   1.5602996e+00 -1.2607950e-01 -4.5270863e+00  2.9653034e+00\n",
      "   5.6978469e+00  1.7867261e+00  9.0346295e-01  7.0495337e-01\n",
      "   2.6810923e+00  4.2743378e+00 -9.9598074e-01 -1.8722837e+00\n",
      "   1.9228293e+00 -7.2615938e+00 -5.9661994e+00  8.2451391e+00\n",
      "   2.6393886e+00  8.0525324e-02 -5.7541651e-01 -1.2452264e+00\n",
      "   2.7321884e-01  3.9579999e-01  1.2603654e+00  1.8978856e+00\n",
      "   1.0581354e+00 -1.3136144e+00  1.4190880e+00  1.7848067e+00\n",
      "  -1.1874753e+00 -1.4837910e+00 -1.8483961e+00  7.4064869e-01\n",
      "  -3.2879169e+00 -1.3570244e+00  4.3589478e+00  1.5607371e+00\n",
      "   1.3384807e+00  2.8039381e-01  1.1386129e+00  1.3377626e-01\n",
      "   3.6440060e-01  2.4644117e+00 -3.7522811e-01  1.0571265e+00\n",
      "  -1.1832542e+00 -5.0374310e-02  1.2136407e+00 -3.2118899e-01\n",
      "  -4.8231453e-01 -1.0542123e+00  3.0117777e-01 -1.9164909e+00\n",
      "   1.4462500e+00  6.2812352e-01 -6.0211265e-01  2.1912541e+00\n",
      "   5.4010445e-01  8.7811184e-01  8.3343095e-01  3.0447152e-01\n",
      "  -3.1240159e-01 -5.6356990e-01 -3.2126442e-01 -8.4462905e-01]]\n",
      "(1, 80)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "[0]\n",
      "['ambulance']\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the pre-trained model\n",
    "siren_CNN_model = load_model('siren_CNN_model.h5')\n",
    "\n",
    "filename = \"sounds/ambulance/sound_6.wav\"\n",
    "audio, sample_rate = librosa.load(filename) \n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=80)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "\n",
    "print(mfccs_scaled_features)\n",
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "print(mfccs_scaled_features)\n",
    "print(mfccs_scaled_features.shape)\n",
    "\n",
    "# Predict the probabilities\n",
    "predicted_probabilities = siren_CNN_model.predict(mfccs_scaled_features)\n",
    "# Get the class with the highest probability\n",
    "predicted_label = np.argmax(predicted_probabilities, axis=1)\n",
    "print(predicted_label)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(['ambulance', 'firetruck', 'traffic'])\n",
    "\n",
    "prediction_class = label_encoder.inverse_transform(predicted_label) \n",
    "print(prediction_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
